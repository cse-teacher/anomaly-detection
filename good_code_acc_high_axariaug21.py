# -*- coding: utf-8 -*-
"""good_code_acc_high_axariaug21.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DVo784SAFTRTyF7KCrzprjgXnCtEaaJp

First step: find potential anomaly nodes
"""

#####plot part fig2
import pandas as pd
import numpy as np
user=[]
for i in range(0,400):
  user.append(i)

calls= pd.read_excel(r'calls.xlsx')
activity=pd.read_excel(r'activity.xlsx')
activity=activity.iloc[:,1:11]

from_calls=calls.iloc[:,1:2]
to_calls=calls.iloc[:,2:3]
duration_calls=calls.iloc[:,4:5]
day_calls=calls.iloc[:,6:7]

from_calls=np.array(from_calls)
to_calls=np.array(to_calls)
duration_calls=np.array(duration_calls)
day_calls=np.array(day_calls)
time=np.zeros((400,))
for i in range(duration_calls.shape[0]):
  if (from_calls[i] in user):
    time[from_calls[i]]=time[from_calls[i]]+duration_calls[i]
  if (to_calls[i] in user):
    time[to_calls[i]]=time[to_calls[i]]+duration_calls[i]

##mean and var
mean_time=np.mean(time,axis=0)
std_time=np.std(time,axis=0)
limit1_time=mean_time-2*std_time
limit2_time=mean_time+2*std_time

index=[]
for i in range(time.shape[0]):
  if (limit1_time <time[i] <limit2_time):
    index.append(i)
activity_anomaly=activity.drop(index,axis=0)

#####plot part fig2
import pandas as pd
import numpy as np
user=[]
for i in range(0,400):
  user.append(i)

calls= pd.read_excel(r'calls.xlsx')
activity=pd.read_excel(r'activity.xlsx')
activity=activity.iloc[:,1:11]
days=[20060601,20060602,20060603,20060604,20060605,20060606,20060607,20060608,20060609,20060610]


from_calls=calls.iloc[:,1:2]
to_calls=calls.iloc[:,2:3]
duration_calls=calls.iloc[:,4:5]
day_calls=calls.iloc[:,6:7]

from_calls=np.array(from_calls)
to_calls=np.array(to_calls)
duration_calls=np.array(duration_calls)
day_calls=np.array(day_calls)
time=np.zeros((400,10))
iid=np.arange(0,400)
for i in range(duration_calls.shape[0]):
  for j in range(len(days)):
    if (day_calls[i]==days[j]) & (from_calls[i] in user):
      time[from_calls[i],j]=time[from_calls[i],j]+duration_calls[i]
    if (day_calls[i]==days[j]) & (to_calls[i] in user):
      time[to_calls[i],j]=time[to_calls[i],j]+duration_calls[i]

time1=pd.DataFrame(time,index=iid)

time1.shape

'''
idxx=[]
for i in indx:
    if i not in idxx:
        idxx.append(i)
'''



###avgg
from numpy.random import seed
from numpy.random import randn
from scipy.stats import anderson
# seed the random number generator
id_x=[]
p_=[]
for i in range(time.shape[0]):
  seed(1)
  result=anderson(time[i,:])
  p=0
  for j in range(len(result.critical_values)):
    sl, cv = result.significance_level[j], result.critical_values[j]
    if result.statistic < result.critical_values[j]:
      print('%.3f: %.3f, data looks normal (fail to reject H0)' % (sl, cv))
    else:
      id_x.append(i)

idxx=[]
for i in id_x:
    if i not in idxx:
        idxx.append(i)

len(idxx)

time1['p_megdar']=p_

######
###indexxx not anomaly
id_no=[]
for i in range(400):
  if i not in id_x:
    id_no.append(i)

'''
idxx=[]
for i in id_x:
    if i not in idxx:
        idxx.append(i)
'''

time1=time1.drop(id_no,axis=0)

time1.shape

mean_t=np.mean(time1,axis=1)
std_t=np.std(time1,axis=1)
mean_t=np.array(mean_t)
std_t=np.array(std_t)
id_x=[]
time2=np.array(time1)
nn=[]
for i in range(time2.shape[0]):
  for j in range(time2.shape[1]):
    if ((time2[i,j]<(std_t[i]/np.abs(mean_t[i])))) :
      id_x.append(i)

idxx=[]
for i in id_x:
    if i not in idxx:
        idxx.append(i)

idxx[0:10]

time_p=time1.sort_values(by=['p_megdar'])
time_p.iloc[0:10,:]



id_x

idxx=[]
for i in indx:
    if i not in idxx:
        idxx.append(i)

### WINRATESMEANDIFF
avgg=np.mean(time,axis=1)
indx=[]

for i in range(time.shape[0]):
  for j in range(time.shape[1]):
    if (np.abs(time[i,j]-avgg[i])<0.5):
      indx.append(i)

idxx=[]
for i in indx:
    if i not in idxx:
        idxx.append(i)

###SKEWNESSN
avgg=np.mean(time,axis=1)
indx=[]

for i in range(time.shape[0]):
  for j in range(time.shape[1]):
    if (((np.abs(time[i,j]-avgg[i])**3)/time.shape[0])<0.7):
      indx.append(i)

idxx=[]
for i in indx:
    if i not in idxx:
        idxx.append(i)

idxx

##skew
##first calculate new matrix
import pandas as pd
import numpy as np



activity=pd.read_excel(r'activity.xlsx')
activity=activity.iloc[:,1:11]
days=[20060601,20060602,20060603,20060604,20060605,20060606,20060607,20060608,20060609,20060610]


freq=np.zeros((400,10))
activity1=np.array(activity)


####find ano
mean_t=np.mean(activity,axis=1)
std_t=np.std(activity,axis=1)
id_x=[]
nn=[]
for i in range(activity.shape[0]):
  for j in range(activity.shape[1]):
    if ((activity1[i,j]<(std_t[i]/np.abs(mean_t[i])))) :
      id_x.append(i)
###second part calculate skew

idxx=[]
for i in id_x:
    if i not in idxx:
        idxx.append(i)

idxx

###save file

from numpy import asarray
from numpy import savetxt

savetxt('tamasha.csv',activity,delimiter=',')

##find anomaly
mean_t=np.mean(time,axis=1)
std_t=np.std(time,axis=1)
id_x=[]

for i in range(time.shape[0]):
  for j in range(time.shape[1]):
    if ((time[i,j]<(mean_t[i]/std_t[i]))) :
      id_x.append(i)

####find ano
mean_t=np.mean(time,axis=1)
std_t=np.std(time,axis=1)
id_x=[]
nn=[]
for i in range(len(mean_t)):
      nn.append((std_t[i]/np.abs(mean_t[i])))

print('zarib tagirat',nn)

idxx=[]
for i in id_x:
    if i not in idxx:
        idxx.append(i)

idxx

##find anomaly
'''
ind=[]
for i in range(time.shape[0]):
  for j in range(time.shape[1]):
    if (0<j<9):
      if (time[i,j]==0) & ((time[i,j+1]>0) | (time[i,j-1]>0)) :
        ind.append(i)
'''

###indexxx not anomaly
id_no=[]
for i in range(400):
  if i not in id_x:
    id_no.append(i)



activity_2=activity.drop(id_no,axis=0)
activity_2.shape

###save file

from numpy import asarray
from numpy import savetxt

savetxt('skew.csv',skew_,delimiter=',')

activity_2.iloc[227:228,:]

"""Second step: define similarity function and label"""

# calculate the Pearson's correlation between two variables
from numpy.random import randn
from numpy.random import seed
from scipy.stats import pearsonr


# calculate Pearson's correlation
corr, _ = pearsonr(list(activity_2.iloc[0:1,:]),list(activity_2.iloc[1:2,:]))
print('Pearsons correlation: %.3f' % corr)

## def similarity
#activity_2=np.array(activity_2)
sum_one=activity_2.sum(axis=1)
mean_sum_one=sum_one.mean(axis=0)

sum_one=np.array(sum_one)
label=np.zeros((activity_2.shape[0],))


for i in range(len(sum_one)):
  if (sum_one[i]<2*mean_sum_one):
    label[i]=0
  else:
    label[i]=1

label

"""Third step: find similarity with lstm autoencoder"""

##define lstm autoencoder
import numpy as np
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
from keras.layers import RepeatVector
from keras.layers import TimeDistributed


# define model
model = Sequential()
model.add(LSTM(128, activation='relu', )input_shape=(1,10, return_sequences=True))
model.add(LSTM(64, activation='relu', return_sequences=False))
model.add(RepeatVector(1))
model.add(LSTM(64, activation='relu', return_sequences=True))
model.add(LSTM(128, activation='relu', return_sequences=True))
model.add(TimeDistributed(Dense(1)))
model.compile(optimizer='adam', loss='mse')
model.summary()

pp=activity_2.index
ppp=np.array(pp)

#activity_2

activity_2=np.array(activity_2)
activity_22=np.c_[ activity_2, ppp ]
#activity_223=activity_22[:,0:10]
activity_22

"""Four step: prepare data for lstm with timesteps and features"""

###def for converting input data into 3-D array as required for LSTM network.

def temporalize(X, y, lookback):
    output_X = []
    output_y = []
    for i in range(len(X)-lookback-1):
        t = []
        for j in range(1,lookback+1):
            # Gather past records upto the lookback period
            t.append(X[[(i+j+1)], :])
        output_X.append(t)
        output_y.append(y[i+lookback+1])
    return output_X, output_y

timesteps = 1
X, y = temporalize(X=activity_22, y = label , lookback = timesteps)

n_features = 11
X = np.array(X)
X = X.reshape(42, timesteps, n_features)

Xxx=X[:,:,0:10]
X_index=X[:,:,10:11]

an_array = np.array([[1, 2, 3], [4, 5, 6]])
second_and_third_column = an_array[:, 1:2]
print(second_and_third_column)

"""This step for fit the model"""

###fit model
from sklearn.model_selection import train_test_split

'''
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
X_train=np.array(X_train)
y_train=np.array(y_train)
'''
XX=np.array(Xxx)
y=np.array(y)
model.fit(XX, y, epochs=69, batch_size=5, verbose=1)
# demonstrate reconstruction
yhat = model.predict(XX, verbose=1)

yhat.shape

yhat=np.reshape(yhat,(42,1))
y_predicted=np.zeros((42,))
for i in range(yhat.shape[0]):
    if yhat[i]>=0.56:
      y_predicted[i]=1
    else:
      y_predicted[i]=0

anomaly_nodes=[]
for i in range(y_predicted.shape[0]):
  if y_predicted[i]==1:
    anomaly_nodes.append(i)

X_index=np.reshape(X_index,(42,))

XXXX=np.reshape(XX,(42,10))
X_f= pd.DataFrame(XXXX,index=X_index)
activity_a=X_f.drop(anomaly_nodes,axis=0)

"""Final step: cluster to find communities"""

from sklearn.cluster import KMeans
import numpy as np

#kmeans = DBSCAN(eps=3,min_samples=2).fit(activity_a)
kmeans = KMeans(n_clusters=10, random_state=0).fit(activity_a)
k_labels=kmeans.fit_predict(activity_a)
k_labels=list(k_labels)

k_labels = kmeans.labels_
labels, counts = np.unique(k_labels, return_counts=True)
print('labels',labels,'counts',counts)

activity_a['cluster_label']=k_labels
zero_labels=activity_a[activity_a["cluster_label"] == 1]
zero_labels

time.shape

in_ac=activity_a.index
in_acc=np.array(in_ac)

s_tt=np.std(activity_a,axis=1)
m_tt=np.mean(activity_a,axis=1)

s_ttt=s_tt-m_tt
activity_a['std_v']=s_ttt
ac_std=activity_a.sort_values(by=['std_v'])
c1_ac_std=ac_std.iloc[32:42,:]

c1_ac_std

activity_a=np.array(activity_a)
m_t=np.mean(activity_a,axis=1)
s_t=np.std(activity_a,axis=1)
one_c=[]
two_c=[]
three_c=[]
for i in range(activity_a.shape[0]):
  for j in range(activity_a.shape[1]):
    if ((activity_a[i,j]<(m_t[i]/s_t[i]))):
      if i not in one_c:
        one_c.append(i)
    elif ((m_t[i]/2*s_t[i])<(activity_a[i,j])<(m_t[i]/s_t[i])):
      if i not in two_c:
        two_c.append(i)
    else:
      if i not in three_c:
        three_c.append(i)

three_c

one=[]
for i in one_c:
    if i.any() not in one:
        one.append(i)

one

activity_a.shape